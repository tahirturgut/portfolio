# -*- coding: utf-8 -*-
"""HW3-TransferLearning-tahirturgut

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IhrRsFrX_6TaACnQXM3EoJFT0DY-HwFh

# CS412 - Machine Learning - 2021
## Homework 3
100 pts


## Goal

The goal of this homework is two-fold:

*   Introduction to the Transfer Learning
*   Gain experience with three dimensional input data (colored images), and pretrained models

## Dataset
[**CelebA**](https://www.cs.toronto.edu/~kriz/cifar.html) is a large-scale face attributes dataset with more than 200K celebrity images, each with 40 attribute annotations. The images in this dataset cover large pose variations and background clutter.

**Download the data from Sucourse and upload it to your Google drive. In your Google drive, you need to have CelebA10k.zip and CelebA10kGender.txt uploaded. (Do not change the name of these files.) Reserve 20% of the training data for validation** and **use the rest for development (learning your models). The official test data (2000 samples) should only be used for testing at the end, and not model selection.**

## Task 
Build a classifier with the Keras library function calls and pretrained models to classify gender in the CelebA dataset.

## Software: 

Keras is a library that we will use especially for deep learning, but also with basic neural network functionality of course.

You may find the necessary function references here: 

http://scikit-learn.org/stable/supervised_learning.html

https://keras.io/api/

https://keras.io/api/applications/

When you search for Conv2d for instance, you should find the relevant function and explained parameters, easily.

## Submission: 
Fill this notebook. Write the report section at the end, removing the part in italics. 

You should prepare a separate pdf document as your homework (name hw3-CS412-yourname.pdf) which consists of the report (Part 8) of the notebook for easy viewing -and- include a link to your notebook from within the pdf report (make sure to include the link obtained from the #share link on top right).

##1) Initialize

*   First make a copy of the notebook given to you as a starter.

*   Make sure you choose Connect form upper right.

## 2) Load training dataset

*  Read from Keras library.
"""

# load data
from google.colab import drive
drive.mount('/content/drive/')

# Commented out IPython magic to ensure Python compatibility.
# import the necessary libraries
import pandas as pd 
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

import keras
import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing import image
# % matplotlib inline

#This will take around 2 to 4 minutes, depends on the internet
import zipfile
zip_ref = zipfile.ZipFile('/content/drive/My Drive/CelebA10k.zip', 'r') # enter the file path on your drive
zip_ref.extractall()
zip_ref.close()

from IPython.display import Image
Image('000001.jpg')

data = pd.read_csv("/content/drive/My Drive/CelebA10klabels.csv") # enter the file path on your drive
print(data.shape)
data.head()

### DO NOT CHANGE THE CODE HERE SO AS TO NOT GET ERRORS
# parameters
ImgSz = 64

# Read training images from text file

labels = []
images = []
for j in range(data.shape[0]):
    labels.append(data["Male"][j])
    #Reading Image
    im = image.load_img(data["5_o_Clock_Shadow"][j])  
    im = im.resize((ImgSz, ImgSz))
    x = image.img_to_array(im) 
    #x = x.reshape((1,) + x.shape) 
    x = np.array(x, dtype="float") / 255.0
    images.append(x)
    
lbls = np.array(labels)
imgs = np.array(images)

x_train = imgs[0:8000]
y_train = lbls[0:8000]
x_test = imgs[8000:]
y_test = lbls[8000:]

x_train.shape, y_train.shape, x_test.shape, y_test.shape

plt.imshow(x_train[1])

"""##3) Visualizing/Understanding the dataset

- Display five random images together with their labels

- Display statistics about the dataset, such as its memory usage, distribution of labels, etc.

"""

# plot random 5 images in your dataset with their labels
import random

fig=plt.figure(figsize=(10,7))

for i in range(1,6):
    randNum = random.randint(0, 10000)
    fig.add_subplot(1,5,i)
    plt.imshow(imgs[randNum])
    gender = "Male" if (lbls[randNum] == 1) else "Female"
    plt.xlabel("label = " + gender)

plt.show()

unique, frequencies = np.unique(y_train, return_counts=True)
print("Pictures with Female Label:", frequencies[0])
print("Pictures with Male Label:", frequencies[1])

flatten_x_train = x_train.reshape(8000,64*64*3)
dummy_x_df = pd.DataFrame(flatten_x_train)
dummy_x_df.info(memory_usage="deep")

"""##4) Split TRAINING data as train (also called development) (80%) and validation (20%) """

# create a datafame to dummy encode and detect categorical loss
y_dict = {'Gender': y_train}
y_train = pd.DataFrame(y_dict)
y_train.head()
y_train = pd.get_dummies(y_train, prefix=['Gender'], columns=['Gender'])

# Split 80-20
from sklearn.model_selection import train_test_split

X_train, X_validation, Y_train, Y_validation = train_test_split(x_train, y_train, test_size=0.2, random_state = 42)

"""## 5) Train Model with Transfer Learning
* Import a pretrained model from keras. By freezing some of its layer weights and/or adding more layers to its output train the model on the dataset. Metaparameters of the model are to be set to default or your own choice. 

* Train two more models by adding at most 5 hidden layers into a pretrained model of your choice. Choose the best model among all the models you trained so far by reporting their performance, together with their runtimes, number parameters, etc.


"""

from keras.applications.vgg16 import VGG16

model_vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(64,64,3))
for layer in model_vgg_conv.layers[-5:]:
   layer.trainable = False
    
model_vgg_conv.summary()

from keras.layers import Input, Flatten, Dense
from keras.models import Model, load_model

# Train your own model with your own choice of parameters, and pretrained model 
keras_input = Input(shape=x_train.shape[1:], name = 'image_input')

output_vgg = model_vgg_conv(keras_input)

vgg1 = Flatten(name='flatten')(output_vgg)
vgg1 = Dense(256, activation='relu', name='fc1')(vgg1)
vgg1 = Dense(128, activation='relu', name='fc2')(vgg1)
vgg1 = Dense(64, activation='relu', name='fc3')(vgg1)
vgg1 = Dense(32, activation='relu', name='fc4')(vgg1)
vgg1 = Dense(2, activation='softmax', name='predictions')(vgg1)

#Create your own model 
pretrained_model1 = Model(inputs=keras_input, outputs=vgg1)
pretrained_model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model using own data
history = pretrained_model1.fit(x_train, y_train, batch_size=64, epochs=5)

#from keras.preprocessing import image
#from keras.applications.vgg16 import preprocess_input
from keras.layers import Input, Flatten, Dense
from keras.models import Model, load_model
# Train your own model with your own choice of parameters, and pretrained model 
keras_input = Input(shape=x_train.shape[1:], name = 'image_input')

output_vgg = model_vgg_conv(keras_input)

vgg2 = Flatten(name='flatten')(output_vgg)
vgg2 = Dense(256, activation='relu', name='fc1')(vgg2)
vgg2 = Dense(64, activation='relu', name='fc2')(vgg2)
vgg2 = Dense(2, activation='softmax', name='predictions')(vgg2)

#Create your own model 
pretrained_model2 = Model(inputs=keras_input, outputs=vgg2)
pretrained_model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Train the model using own data
history = pretrained_model2.fit(x_train, y_train, batch_size=64, epochs=5)

score = pretrained_model1.evaluate(X_validation, Y_validation)
print("Accuracy of first model on validation set: ", score[1])
score = pretrained_model2.evaluate(X_validation, Y_validation)
print("Accuracy of second model on validation set: ", score[1])

"""## 6) Test your classifier on Test set

- Apply same pre-processing as training data
- Predict the labels of testing data **using the best model that you have selected according to your validation results** and report the accuracy. 
"""

# Load test data
y_dict = {'Gender': y_test}
y_test = pd.DataFrame(y_dict)
y_test = pd.get_dummies(y_test, prefix=['Gender'], columns=['Gender'])

# Predict
score = pretrained_model2.evaluate(x_test, y_test)
print("Accuracy of main model on test set: ", score[1])

"""##7) Report Your Results

**Notebook should be RUN:** As training and testing may take a long time, we may just look at your notebook results; so make sure **each cell is run**, so outputs are there.

**Report:** Write an **one page summary** of your approach to this problem **below**; this should be like an abstract of a paper or the executive summary (you aim for clarity and passing on information, not going to details about known facts such as what CNN is or what transfer learning is, assuming they are known to people in your research area). 

**Must include statements such as those below:**
**(Remove the text in bullet points, below, and include your own report)**

* Include the **problem definition**: 1-2 lines.

* Talk about your **approach** - the pretrained network and its architecture, changes to the architecture, what is finetuned and for how many epochs...

* Give your **experimental setup** (train/val/test sets, size and how split, samples) and results - along with some analysis of the errors (just take a look at some of your errors and say a few things)

* **Anything else?** You can comment on the speed, computational resources, or anything else that you deem important/interesting. 

* You can add **additional visualization as separate pages **if you want, think of them as appendix, keeping the one-page as abstract/summary.

* Mention **Bonus part** here - in 1-2 paragraphs at most.

##8) (Bonus 5 pts) Train Convolutional neural networks first on development data


* Train a convolutional neural network from scratch (not transfer learning) with number of hidden layers and neurons of **your choice**. Rest of the parameters are to be set to default or your own choice. 

* The aim of this part is to establish an insight for convolutional neural networks and to see why we use them.
"""

# Train CNNs


# Report your results