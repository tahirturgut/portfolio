{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Turgut_Tahir_hw4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKD90mb9fjH2"
      },
      "source": [
        "# Homework 4: Random Forests\r\n",
        "\r\n",
        "*In this homework, you will work with a Speed Dating Dataset and apply the Random Forest model on the dataset after establishing preprocessing tasks.*\r\n",
        "\r\n",
        "**Submission Instructions**\r\n",
        "\r\n",
        "---\r\n",
        "It is important that you follow the submission instructions. \r\n",
        "1. Copy this assignment notebook to your Drive. <font color = 'red'> `File` --> `Save a copy in Drive`</font>. Rename it as <font color = 'green'>`Lastname_Firstname_hw4`</font>.\r\n",
        "\r\n",
        "2. Write your solutions in the cells  marked <font color = 'green'>`# your code`</font>.\r\n",
        "\r\n",
        "3. **Do not delete your outputs. They are essential for the grading. Make sure that cells containing your solutions are executed, and the results are displayed on the notebook.**\r\n",
        "\r\n",
        "4. When you're done please submit your solutions as an <font color=\"red\">`.ipynb`</font> file. To do so:\r\n",
        "\r\n",
        "  - Click on <font color=\"red\">`File`</font>  at the top left on the Colab screen, then click on <font color = 'red'>`Download .ipynb`</font>.\r\n",
        "  - Then submit the downloaded <font color=\"red\">`.ipynb`</font> version of your work on SUCourse.\r\n",
        "\r\n",
        "\r\n",
        "For any question, you may send an email to your TAs and LAs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM1mnUs9fnSR"
      },
      "source": [
        "__________________________________\r\n",
        "## Dataset Description\r\n",
        "\r\n",
        "![](https://www.xfactordates.com/wp-content/uploads/2019/06/speeddating-1205-RGB-1-780x415.jpg)\r\n",
        "\r\n",
        "In this homework, you will work on a simplified version of the [Speed Dating Experiment dataset from Kaggle](https://www.kaggle.com/annavictoria/speed-dating-experiment). \r\n",
        "\r\n",
        "Each instance in the dataset denotes a speed date between a participant and an assigned partner. For clarity, the descriptions below call the first participant as the main participant and the second participant as the assigned participant. \r\n",
        "\r\n",
        "The first 8 attributes in the dataset give information about the participants and their speed date assignment in the whole event. Among these attributes, ones that are not self-explanatory are described below.\r\n",
        "\r\n",
        "```\r\n",
        "iid: Unique participant number,\r\n",
        "pid: Unique assigned partner number\r\n",
        "wave: Number of the session where date took place\r\n",
        "round: Number of people that met in wave\r\n",
        "position: Station number where met partner (You can consider this like table number)\r\n",
        "order: The number of date that night when met partner\r\n",
        "```\r\n",
        "\r\n",
        "After these features, we have the attributes regarding the preferences and scores of both the participant and the other assigned participant. Here, the easiest way to understand whether an attribute is for the main participant or the assigned participant is from the names of these attributes. Attributes including the `_o` in them belong to the assigned participants. To explain this further, below are attributes showing the scores given to the assigned participant by the main participant.\r\n",
        "\r\n",
        "```\r\n",
        "These are score attributes given to assigned partner (from 1 to 10)\r\n",
        "attr: Rating of attractiveness\r\n",
        "sinc: Rating of sincerity\r\n",
        "intel: Rating of intelligence\r\n",
        "fun: Rating of how fun the person is\r\n",
        "amb: Rating of ambitiousness\r\n",
        "shar: Rating of shared interests\r\n",
        "like: Rating of liking the person\r\n",
        "prob: Rating of probability of further dates with the person\r\n",
        "```\r\n",
        "\r\n",
        "As explained above, this time, the following attributes are scores given to the main participant by the assigned participant: `attr_o, sinc_o, intel_o, fun_o, amb_o, shar_o, like_o, prob_o`.\r\n",
        "\r\n",
        "In addition to these features, you will also see numbered features like `attr2_1` or `sinc3_1`. For these features, the first number denotes the context of these attributes. Below, you can see the questions asked to participants for these attributes.\r\n",
        "\r\n",
        "```\r\n",
        "Question 1: Please rate the importance of the following attributes in a potential date.\r\n",
        "(Total 100 points are distributed among features below.)\r\n",
        "  - attr1_1, sinc1_1, intel1_1, fun1_1, amb1_1, shar1_1 are responses of participants to the Question 1\r\n",
        "\r\n",
        "Question 2: What do you think the opposite sex looks for in a date?\r\n",
        "(Total 100 points are distributed among features below.)\r\n",
        "  - attr2_1, sinc2_1, intel2_1, fun2_1, amb2_1, shar2_1 are responses of participants to the Question 2\r\n",
        "\r\n",
        "Question 3: How do you think you measure up?\r\n",
        "(From 1 to 10 for each feature)\r\n",
        "  - attr3_1, sinc3_1, intel3_1, fun3_1, amb3_1, shar3_1 are responses of participants to the Question 3\r\n",
        "```\r\n",
        "\r\n",
        "The second number denotes the time of feature being recorded. As these features are recorded multiple times during and after the event, \r\n",
        "in the original dataset there are features with different record times. In our simplified version, we only selected the initial answers of these individuals, so that the second number in these features are always 1.  \r\n",
        "\r\n",
        "Additionally, there are features coded as `pf_o_attr, pf_o_sin, pf_o_int, pf_o_fun, pf_o_amb, pf_o_sha`. These features denote the initial preferences of the assigned participant in a potential date *(Total 100 points are distributed among features)*.\r\n",
        "\r\n",
        "Most of the features in the dataset consist of numeric ordinal values. After establishing the tasks introduced in the Data Preprocessing, the dataset is almost ready to be applied to machine learning models.\r\n",
        "\r\n",
        "In the machine learning part, we will be interested in predicting the decision of the participants' to continue dating the assigned partner. Values for information are stored in the `dec` attribute. Similar to the attributes described earlier, we also have assigned partners' decisions stored in the `dec_o` attribute.\r\n",
        "\r\n",
        "For other features and further information about the attributes, you can visit the Kaggle page for the dataset and check the Data Key file shared there. However, please note that the dataset used in this homework is a simplified format of the original dataset to make your processes easier. Because of this, some of the attributes documented in the Data Key file may not be in the dataset shared with you.\r\n",
        "\r\n",
        "________________________________"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp-MELUQATeL",
        "outputId": "21c19a57-53d0-45ec-bf14-04acdbe5df34"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount(\"./drive\", force_remount= True)\r\n",
        "\r\n",
        "path_prefix = \"./drive/My Drive\""
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at ./drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JupvmkzAUYc"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from os.path import join\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "EIgdF02oAW_4",
        "outputId": "405cfb2c-4352-4be5-aaab-bd569fb0096c"
      },
      "source": [
        "fname = \"SpeedDatingData.csv\"\r\n",
        "df = pd.read_csv(join(path_prefix, fname))\r\n",
        "df.head()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>iid</th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>wave</th>\n",
              "      <th>round</th>\n",
              "      <th>position</th>\n",
              "      <th>order</th>\n",
              "      <th>pid</th>\n",
              "      <th>samerace</th>\n",
              "      <th>age_o</th>\n",
              "      <th>pf_o_att</th>\n",
              "      <th>pf_o_sin</th>\n",
              "      <th>pf_o_int</th>\n",
              "      <th>pf_o_fun</th>\n",
              "      <th>pf_o_amb</th>\n",
              "      <th>pf_o_sha</th>\n",
              "      <th>dec_o</th>\n",
              "      <th>attr_o</th>\n",
              "      <th>sinc_o</th>\n",
              "      <th>intel_o</th>\n",
              "      <th>fun_o</th>\n",
              "      <th>amb_o</th>\n",
              "      <th>shar_o</th>\n",
              "      <th>like_o</th>\n",
              "      <th>prob_o</th>\n",
              "      <th>met_o</th>\n",
              "      <th>age</th>\n",
              "      <th>undergra</th>\n",
              "      <th>mn_sat</th>\n",
              "      <th>tuition</th>\n",
              "      <th>imprace</th>\n",
              "      <th>imprelig</th>\n",
              "      <th>from</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>income</th>\n",
              "      <th>goal</th>\n",
              "      <th>date</th>\n",
              "      <th>go_out</th>\n",
              "      <th>sports</th>\n",
              "      <th>tvsports</th>\n",
              "      <th>...</th>\n",
              "      <th>gaming</th>\n",
              "      <th>clubbing</th>\n",
              "      <th>reading</th>\n",
              "      <th>tv</th>\n",
              "      <th>theater</th>\n",
              "      <th>movies</th>\n",
              "      <th>concerts</th>\n",
              "      <th>music</th>\n",
              "      <th>shopping</th>\n",
              "      <th>yoga</th>\n",
              "      <th>exphappy</th>\n",
              "      <th>expnum</th>\n",
              "      <th>attr1_1</th>\n",
              "      <th>sinc1_1</th>\n",
              "      <th>intel1_1</th>\n",
              "      <th>fun1_1</th>\n",
              "      <th>amb1_1</th>\n",
              "      <th>shar1_1</th>\n",
              "      <th>attr2_1</th>\n",
              "      <th>sinc2_1</th>\n",
              "      <th>intel2_1</th>\n",
              "      <th>fun2_1</th>\n",
              "      <th>amb2_1</th>\n",
              "      <th>shar2_1</th>\n",
              "      <th>attr3_1</th>\n",
              "      <th>sinc3_1</th>\n",
              "      <th>fun3_1</th>\n",
              "      <th>intel3_1</th>\n",
              "      <th>amb3_1</th>\n",
              "      <th>dec</th>\n",
              "      <th>attr</th>\n",
              "      <th>sinc</th>\n",
              "      <th>intel</th>\n",
              "      <th>fun</th>\n",
              "      <th>amb</th>\n",
              "      <th>shar</th>\n",
              "      <th>like</th>\n",
              "      <th>prob</th>\n",
              "      <th>met</th>\n",
              "      <th>match_es</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Chicago</td>\n",
              "      <td>60,521</td>\n",
              "      <td>69,487.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Chicago</td>\n",
              "      <td>60,521</td>\n",
              "      <td>69,487.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1</td>\n",
              "      <td>22.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Chicago</td>\n",
              "      <td>60,521</td>\n",
              "      <td>69,487.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Chicago</td>\n",
              "      <td>60,521</td>\n",
              "      <td>69,487.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Chicago</td>\n",
              "      <td>60,521</td>\n",
              "      <td>69,487.00</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 85 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   iid   id  gender  wave  round  ...  shar  like  prob  met  match_es\n",
              "0    1  1.0       0     1     10  ...   5.0   7.0   6.0  2.0       4.0\n",
              "1    1  1.0       0     1     10  ...   6.0   7.0   5.0  1.0       4.0\n",
              "2    1  1.0       0     1     10  ...   7.0   7.0   NaN  1.0       4.0\n",
              "3    1  1.0       0     1     10  ...   8.0   7.0   6.0  2.0       4.0\n",
              "4    1  1.0       0     1     10  ...   6.0   6.0   6.0  2.0       4.0\n",
              "\n",
              "[5 rows x 85 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFPWP8xHB8gd"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yx9l9I-BO6kL"
      },
      "source": [
        "### Discarding Missing Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7J1hB365O_4a"
      },
      "source": [
        "#### Task 1: Missing Attribute Values\r\n",
        "\r\n",
        "As the dataset in this homework is mostly built with survey answers, some of the attributes contain missing values. Although we can deal with these attributes without discarding them, it may be more beneficial to drop the ones having a lot of `NaN` values in them.\r\n",
        "\r\n",
        "Your first task here is to display the attributes in which more than half of the instances are missing (i.e. `NaN`). Then drop these attributes from the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLviZRpRQTdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4f6047d-256d-4cac-cc2d-203e554a66e8"
      },
      "source": [
        "#check each column's nan value and if it is greater than 4189, drop that column\r\n",
        "for col in df.columns:\r\n",
        "  if (df[col].isnull().sum() > len(df)/2):\r\n",
        "    print(\"Column {} has more than half of the instances(4189) are NaN\".format(col))\r\n",
        "    df = df.drop([col], axis=1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column mn_sat has more than half of the instances(4189) are NaN\n",
            "Column tuition has more than half of the instances(4189) are NaN\n",
            "Column expnum has more than half of the instances(4189) are NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-hLj9PWPJcj"
      },
      "source": [
        "#### Task 2: Rows with Missing Values\r\n",
        "\r\n",
        "Some of the rows in the dataset also contain a lot of missing attribute values. In such occurrences, it probably means that the details about the particular speed date were not recorded properly. Because of this, we should discard rows where the majority of the values are missing.\r\n",
        "\r\n",
        "Your task is to discard rows in which the number of missing attribute values (`NaN` values) is more than half of the number of total attributes.\r\n",
        "\r\n",
        "*hint: You can also check the number of missing values in a row by using `df.isnull().sum()` by passing the correct `axis` parameter value to the sum function.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sKacxbwF3E9"
      },
      "source": [
        "#create a temp array to store rows with greater NaN value count than threshold\r\n",
        "majornan_rows= (df.isnull().sum(axis = 1) > df.shape[1]/2)\r\n",
        "#drop all of the \"true\" (which means majority is NaN rather than non-NaN) rows\r\n",
        "for i in range(len(majornan_rows)):\r\n",
        "  if majornan_rows[i] == True:\r\n",
        "    df = df.drop([i])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qQoqx12PTDV"
      },
      "source": [
        "### Fixing Attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1bTZcUpPVkq"
      },
      "source": [
        "#### Task 3: Fixing `date` and `go_out`\r\n",
        "\r\n",
        "If you check the `Speed Dating Data Key` file, you can see that entries in the `date` and `go_out` attributes are encoded as below.\r\n",
        "\r\n",
        "```\r\n",
        "date:\r\n",
        "In general, how frequently do you go on dates? \r\n",
        "\tSeveral times a week=1\r\n",
        "\tTwice a week=2\r\n",
        "\tOnce a week=3\r\n",
        "\tTwice a month=4\r\n",
        "\tOnce a month=5\r\n",
        "\tSeveral times a year=6\r\n",
        "\tAlmost never=7\r\n",
        "\r\n",
        "go_out:\r\n",
        "How often do you go out (not necessarily on dates)?\r\n",
        "\tSeveral times a week=1\r\n",
        "\tTwice a week=2\r\n",
        "\tOnce a week=3\r\n",
        "\tTwice a month=4\r\n",
        "\tOnce a month=5\r\n",
        "\tSeveral times a year=6\r\n",
        "\tAlmost never=7\r\n",
        "\r\n",
        "```\r\n",
        "\r\n",
        "Here, the maximum value 7 is used for describing answers with minimum values to these questions. Keeping these attributes as they are disrupting the ordinality built in these attributes. To obtain correct ordinality for `date` and `go_out` the minimum value for these attributes should be for `Almost never`.\r\n",
        "\r\n",
        "To fix this, your task is to convert the value `7` in these attributes to value `0`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiVjcXY-Z966"
      },
      "source": [
        "#use replace method to fix ambiguity problem\r\n",
        "df['date'] = df['date'].replace(7,0)\r\n",
        "df['go_out'] = df['go_out'].replace(7,0)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpFgm7kkPeGJ"
      },
      "source": [
        "#### Task 4: Fixing `goal`\r\n",
        "\r\n",
        "When you check the `Speed Dating Data Key` file, you can see that entries in the `goal` attributes are encoded as below.\r\n",
        "\r\n",
        "```\r\n",
        "goal:\r\n",
        "What is your primary goal in participating in this event? \r\n",
        "\tSeemed like a fun night out=1\r\n",
        "\tTo meet new people=2\r\n",
        "\tTo get a date=3\r\n",
        "\tLooking for a serious relationship=4\r\n",
        "\tTo say I did it=5\r\n",
        "\tOther=6\r\n",
        "```\r\n",
        "\r\n",
        "Unlike the earlier two attributes, `date` and `go_out`, `goal` attribute does not look like it is an ordinal feature. Because of this, leaving values as is, ordered from 1 to 6, implies that there is a hierarchy between the values.\r\n",
        "\r\n",
        "To fix this, use one-hot-encoding to create one-hot features from the `goal` attribute. However, as `goal` attribute includes `NaN` values currently, we cannot directly use One-Hot-Encoding. We need to deal with the missing values first.\r\n",
        "\r\n",
        "Your Task:\r\n",
        "  - Fill the missing values with value `6` *(denotes to `other`)*\r\n",
        "  - Create one-hot features from `goal` attribute,\r\n",
        "  - Name these features `goal_fun, goal_meet, goal_date, goal_serious, goal_did, goal_other` respectively,\r\n",
        "  - Add these features to the dataframe,\r\n",
        "  - Lastly, discard the initial `goal` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scrWt2WqqHKI"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "df[\"goal\"] = df[\"goal\"].fillna(6)\r\n",
        "\r\n",
        "y = OneHotEncoder().fit_transform(df.goal.values.reshape(-1,1)).toarray()\r\n",
        "new_features = ['goal_fun', 'goal_meet', 'goal_date', 'goal_serious', 'goal_did', 'goal_other']\r\n",
        "for i in range(6):\r\n",
        "  df[new_features[i]] = y[:,i]\r\n",
        "\r\n",
        "df = df.drop(['goal'], axis=1)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc_VOWE3a0F1"
      },
      "source": [
        "#### Task 5: Rest of the `NaN` Values\r\n",
        "\r\n",
        "As most of the features in the dataset consist of numeric ordinal values, one solution for `NaN` values can be filling with the median values.\r\n",
        "\r\n",
        "- Check if there are `object` typed attributes in the dataset.\r\n",
        "- If possible, convert them to `float` type.\r\n",
        "- Then, discard columns with string values.\r\n",
        "- Lastly, fill the remaining missing values in the dataset with corresponding column median values.\r\n",
        "\r\n",
        "*hint: To get attributes with string values, you can check attributes which do not have the data type of `float64`.*\r\n",
        "\r\n",
        "*hint 2: You may not be able to convert `income` values to float directly. To be able do that, you can omit the `,` in the initial income values.*\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSUP_ijB5Ssm"
      },
      "source": [
        "df = df.replace(',','', regex=True)\r\n",
        "for col in df.columns:\r\n",
        "  df[col] = df[col].apply(pd.to_numeric,errors='ignore')  #if possible convert them to float64\r\n",
        "\r\n",
        "for col in df.columns:\r\n",
        "  if (df[col].dtype == 'object'):   #if there is still unconverted columns\r\n",
        "    df = df.drop([col], axis=1)    #drop those columns\r\n",
        "  else:\r\n",
        "    df[col] = df[col].fillna(df[col].median())    #fill the NaN values with median"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hlaUWT95rHI"
      },
      "source": [
        "## Applying Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F43TaFYNdZ3V"
      },
      "source": [
        "#### Task 1: Dropping Unnecessary Attributes\r\n",
        "\r\n",
        "Before moving on to applying machine learning, we need to discard features which do not yield any information about the problem we want to analyze with machine learning. As we want to predict the decision of the participant on dating, the attributes below are redundant.\r\n",
        "\r\n",
        "Discard the redundant attributes listed below from the dataframe.\r\n",
        "\r\n",
        "```\r\n",
        "iid, id, wave, round, position, order\r\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItOrd-YZ4_iW"
      },
      "source": [
        "#dropping the columns redundant\r\n",
        "df = df.drop(['iid', 'id', 'wave', 'round', 'position', 'order'], axis=1)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYcXE8E4dZu0"
      },
      "source": [
        "#### Task 2: Initial Random Forest Model\r\n",
        "\r\n",
        "With the instructions below, build the initial Random Forest model.\r\n",
        "\r\n",
        "1. Split the dataset into 80% training, 10% validation and 10% test set with `random_state` parameter set to a value different than 0.\r\n",
        "2. Build a Random Forest model with `criterion` set to `entropy`.\r\n",
        "3. Train the model on the training set.\r\n",
        "4. Report the accuracy on the validation set.\r\n",
        "\r\n",
        "*Necessary import statements are given for you in the cell below.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VGFEMV6yL-m"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9QYw_umSGD-"
      },
      "source": [
        "#split the data that:\r\n",
        "X = df.drop(\"dec\",axis=1)   #features to be used in prediction\r\n",
        "y = df[\"dec\"] #feature to be predicted"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F6Q4rzyyDmp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ea89d71-36ff-4268-efe3-5207eada275f"
      },
      "source": [
        "# %80 to %20 split\r\n",
        "X_train, X_test_valid, y_train, y_test_valid = train_test_split(X, y, test_size=0.2,random_state=40)\r\n",
        "# %10 and %10 split\r\n",
        "X_test, X_valid, y_test, y_valid = train_test_split(X_test_valid, y_test_valid, test_size=0.5,random_state=40)\r\n",
        "\r\n",
        "#Random forest application\r\n",
        "model_rf = RandomForestClassifier(random_state=40, criterion='entropy')\r\n",
        "model_rf.fit(X_train, y_train,)\r\n",
        "\r\n",
        "#prediction accuracy rate\r\n",
        "rf_predictions = model_rf.predict(X_valid)\r\n",
        "rf_acc = accuracy_score(y_valid, rf_predictions)\r\n",
        "\r\n",
        "print(\"Random Forest Accuracy:\"+str(rf_acc))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest Accuracy:0.8361445783132531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8xGkB3JdZha"
      },
      "source": [
        "#### Task 3: Feature Importances\r\n",
        "\r\n",
        "Importance of features from a Random Forest model can be checked after the training is complete. To do that, you can use the `feature_importances_` attribute of a Random Forest model instance.\r\n",
        "\r\n",
        "To analyze importances of different features in our dataset, plot the most important 25 features of the model you trained above in a horizontal bar chart. You can use the plot below for referencing.\r\n",
        "\r\n",
        "![](https://linkpicture.com/q/features.png)\r\n",
        "\r\n",
        "To achieve the colors of the plot, it was built with a certain colormap existing in matplotlib library. To obtain a colormap from matplotlib, you can use `cm.NameOfTheColorMap` and create a colormap instance. You can also pass a `np.linspace` as a parameter to a colormap, with the number of data instances you want to plot. This way, you can create a certain amount of colors to pass as a `color` parameter to the bar chart.\r\n",
        "\r\n",
        "*You can check available colormaps from the matplotlib [documentation link](https://matplotlib.org/3.3.3/tutorials/colors/colormaps.html).* \r\n",
        "\r\n",
        "*Necessary import statement is given for you in the cell below.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUG7u47k8NIC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "0299658c-0073-4451-deac-3783e68a2e45"
      },
      "source": [
        "from matplotlib import cm\r\n",
        "import matplotlib.colors as colors\r\n",
        "\r\n",
        "#match importance score with column names\r\n",
        "dict_importances = {}\r\n",
        "importances = model_rf.feature_importances_\r\n",
        "for i in range(len(importances)):\r\n",
        "  dict_importances[X.columns[i]] = importances[i]\r\n",
        "\r\n",
        "#sort the dictionary according to scores\r\n",
        "dict_importances = sorted(dict_importances.items(), key=lambda x: x[1])\r\n",
        "labels = [i for i,j in dict_importances]\r\n",
        "importances = [j for i,j in dict_importances]\r\n",
        "\r\n",
        "my_cmap = plt.get_cmap(\"Reds\")\r\n",
        "\r\n",
        "#plot the first 20 indices of dict's keys and values, with cmp 'Reds'\r\n",
        "fig, ax = plt.subplots(figsize=(10,5))\r\n",
        "ax.barh(labels[-20:], importances[-20:], color=my_cmap(np.linspace(0,1,len(importances[-20:]))))\r\n",
        "ax.grid(True)\r\n",
        "ax.set_title(\"Most Important 20 Features of the Initial Model\")\r\n",
        "ax.set_xlabel(\"Feature Importance\")\r\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZDJZee15v1s"
      },
      "source": [
        "## Grid Search\r\n",
        "\r\n",
        "Grid search is one of the existing approaches to hyperparameter tuning for machine learning models. With Grid Search, we methodically build and evaluate a model for each combination of parameter space specified in a grid. This allows us to obtain the best performing hyperparameter options for the model we want to use.\r\n",
        "\r\n",
        "sklearn library does have an implementation of Grid Search method available for all of its model. You can check the Grid Search from the sklearn [documentation link](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fT7NnFg70du"
      },
      "source": [
        "### Task 1: Selecting Optimum Parameters\r\n",
        "\r\n",
        "Apply Grid Search for the initial Random Forest model with the given parameter space below.\r\n",
        "\r\n",
        "```\r\n",
        "n_estimators: 100, 200, 300\r\n",
        "min_samples_split: 2, 4\r\n",
        "```\r\n",
        "\r\n",
        "- Train Random Forest instances with the given parameter space using GridSearchCV,\r\n",
        "- Show the hyperparameters best performing model on the training set using `best_params_` attribute,\r\n",
        "- Predict validation instances with best performing hyperparameters,\r\n",
        "- Compare the accuracy score you obtained here with the accuracy score of the initial model.\r\n",
        "- Use the markdown cell for your comments.\r\n",
        "\r\n",
        "*hint: If you use `grid_search_object.predict()` it uses the model instance which performs best on the training set.*\r\n",
        "\r\n",
        "*Necessary import statement is given for you in the cell below.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE4eKk0VyZoR"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfR02zDTeLuh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03fb3920-02d8-4063-fd61-579f803acde1"
      },
      "source": [
        "#parameters to be compared\r\n",
        "param_grid = {\"n_estimators\":[100, 200, 300], \"min_samples_split\":[2, 4]}\r\n",
        "\r\n",
        "rf_grid = GridSearchCV(estimator = model_rf, param_grid = param_grid)\r\n",
        "rf_grid.fit(X_train, y_train)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=None, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='entropy',\n",
              "                                              max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False, random_state=40,\n",
              "                                              verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'min_samples_split': [2, 4],\n",
              "                         'n_estimators': [100, 200, 300]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2LWRRLZGF6p"
      },
      "source": [
        "With given parameters, accuracy score was: 0.8361445783132531.\r\n",
        "\r\n",
        "It increases to 0.8493975903614458 with using gridsearch cross validation.\r\n",
        "\r\n",
        "The increase is slight, so the parameters that given at first place was already good enough."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8kSSxObES85",
        "outputId": "191bfa1c-cc6a-4f6b-986b-91c7077b6a14"
      },
      "source": [
        "# Displaying best hyperparameters\r\n",
        "rf_grid.best_params_"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'min_samples_split': 2, 'n_estimators': 300}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WREMQGMJEb7W",
        "outputId": "959c8175-ad9c-432d-e9fb-4dc4987442e3"
      },
      "source": [
        "# Accuracy score with new hyperparameters\r\n",
        "grid_preds = rf_grid.predict(X_valid)\r\n",
        "accuracy_score(y_valid, grid_preds)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8493975903614458"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw2uBXlt74sc"
      },
      "source": [
        "### Task 2: Confusion Matrix\r\n",
        "\r\n",
        "By using the best performing hyper-parameters from the earlier task, Check the accuracy score of the model on the test set. Lastly, evaluate the performance of the model on the test set by checking the confusion matrix. Use the cell given to you below for your evaluation.\r\n",
        "\r\n",
        "*Necessary import statement is given for you in the cell below.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq4HnvgpGfEg"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UqqxgNw79SH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c31a675d-5479-48d7-87ae-249f21574848"
      },
      "source": [
        "mat = confusion_matrix(y_test, grid_preds)\r\n",
        "print(mat)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[308 205]\n",
            " [191 126]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiXTxiqGGS9R"
      },
      "source": [
        "True predictions are: 308 (0/0) and 126 (1/1)\r\n",
        "\r\n",
        "False ones are: 205 (Guessing 1, but actually 0) and 191 (Guessing 0 for 1) \r\n",
        "\r\n",
        "Therefore in total: (308+126)\\(308+126+205+191) ~= 0.52\r\n",
        "\r\n",
        "Success of 0's: 308/308+205 ~= 0.60\r\n",
        "\r\n",
        "Success of 1's: 126/126+191 ~= 0.397\r\n",
        "\r\n",
        "It can be concluded that predicting 0's are more accomplished than predicting 1's by this random forest model. Also, total ratio is close to %50 and there is only two option. Therefore, model should be developed further in order to obtain more accomplished prediction"
      ]
    }
  ]
}